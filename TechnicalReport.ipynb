{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable\n",
    "\n",
    "# uncomment once you paste your myclassifiers.py into mysklearn package\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "# Initialize the KNeighborsClassifier\n",
    "knn_classifier = MyKNeighborsClassifier()\n",
    "dummy_classifier = MyDummyClassifier()\n",
    "naive_class = MyNaiveBayesClassifier()\n",
    "tree_classifier = MyDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 3407: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the table from a CSV file\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mMyPyTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv_to_mypytable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_file/fifa_players.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Filter out rows where the overall rating is less than 70\u001b[39;00m\n\u001b[0;32m     10\u001b[0m rating_column \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mget_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverall_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jack\\OneDrive\\Documents\\Code\\CPSC322\\CPSC322-Final-Project\\mysklearn\\mypytable.py:483\u001b[0m, in \u001b[0;36mMyPyTable.csv_to_mypytable\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m    480\u001b[0m     column_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(reader)\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# Read the data rows\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m     data \u001b[38;5;241m=\u001b[39m [row \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader]\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# Create a MyPyTable with the read column names and data\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MyPyTable(column_names\u001b[38;5;241m=\u001b[39mcolumn_names, data\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\jack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 3407: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "seed(42)\n",
    "\n",
    "# Load the table from a CSV file\n",
    "table = MyPyTable().csv_to_mypytable(\"input_file/fifa_players.csv\")\n",
    "\n",
    "# Filter out rows where the overall rating is less than 70\n",
    "rating_column = table.get_column(\"overall_rating\")\n",
    "indexes_to_drop = [index for index, rating in enumerate(rating_column) if int(rating) < 70]\n",
    "print(f\"Rows to drop (rating < 70): {indexes_to_drop}\")\n",
    "print(\"Size before filtering: \", len(table.data))\n",
    "table.drop_rows(indexes_to_drop)\n",
    "print(\"Size after filtering: \", len(table.data))\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_remove = [\n",
    "    \"name\", \"full_name\", \"birth_date\", \"age\", \"weight_kgs\", \"nationality\",\n",
    "    \"overall_rating\", \"potential\", \"value_euro\", \"wage_euro\", \"preferred_foot\",\n",
    "    \"international_reputation(1-5)\", \"weak_foot(1-5)\", \"body_type\", \"release_clause_euro\",\n",
    "    \"national_team\", \"national_rating\", \"national_team_position\", \"national_jersey_number\",\n",
    "    \"heading_accuracy\", \"volleys\", \"curve\", \"sprint_speed\", \"reactions\", \"balance\",\n",
    "    \"jumping\", \"strength\", \"aggression\", \"penalties\", \"composure\", \"sliding_tackle\"\n",
    "]\n",
    "for column in columns_to_remove:\n",
    "    if column in table.column_names:  # Check if column exists before removing\n",
    "        table.remove_column(column)\n",
    "\n",
    "# Discretize positions\n",
    "positions = table.get_column(\"positions\")\n",
    "discretized_positions = [myutils.classify_position(position) for position in positions]\n",
    "table.add_column(\"discretized_position\", discretized_positions)\n",
    "print(\"Discretized positions added to the table.\")\n",
    "\n",
    "# Separate data by position\n",
    "goalkeepers = [row for row in table.data if row[-1] == \"Goalkeeper\"]\n",
    "defenders = [row for row in table.data if row[-1] == \"Defender\"]\n",
    "forwards = [row for row in table.data if row[-1] == \"Forward\"]\n",
    "midfielders = [row for row in table.data if row[-1] == \"Midfielder\"]\n",
    "\n",
    "# Downsample defenders, forwards, and midfielders to the size of goalkeepers\n",
    "gk_size = len(goalkeepers)\n",
    "if gk_size > 0:  # Ensure goalkeepers are not empty\n",
    "    defenders_downsampled = sample(defenders, min(gk_size, len(defenders)))\n",
    "    forwards_downsampled = sample(forwards, min(gk_size, len(forwards)))\n",
    "    midfielders_downsampled = sample(midfielders, min(gk_size, len(midfielders)))\n",
    "else:\n",
    "    print(\"No goalkeepers found, cannot balance data.\")\n",
    "    defenders_downsampled, forwards_downsampled, midfielders_downsampled = [], [], []\n",
    "\n",
    "# Combine the downsampled data\n",
    "balanced_data = goalkeepers + defenders_downsampled + forwards_downsampled + midfielders_downsampled\n",
    "print(\"Balanced data size: \", len(balanced_data))\n",
    "\n",
    "# Update the table with the balanced data\n",
    "table.data = balanced_data\n",
    "\n",
    "# Print final table size and data\n",
    "print(\"Final table size: \", len(table.data))\n",
    "table.pretty_print()\n",
    "\n",
    "# Print dummy classifier baseline (25%)\n",
    "dummy_baseline = 0.25\n",
    "print(f\"Dummy classifier baseline (25%): {dummy_baseline}\")\n",
    "\n",
    "# Add a new column before extracting column indices\n",
    "new_column_name = \"custom_metric\"\n",
    "new_column_values = [row[0] * 2 for row in table.data]  # Example transformation of an existing column\n",
    "if len(new_column_values) == len(table.data):  # Ensure values match the data length\n",
    "    table.add_column(new_column_name, new_column_values)\n",
    "else:\n",
    "    print(\"Error: Mismatched column size for 'custom_metric'.\")\n",
    "\n",
    "# Update naive_class.header to include the new column\n",
    "naive_class.header = [\n",
    "    \"height_cm\",\n",
    "    \"positions\",\n",
    "    \"skill_moves(1-5)\",\n",
    "    \"crossing\",\n",
    "    \"finishing\",\n",
    "    \"short_passing\",\n",
    "    \"dribbling\",\n",
    "    \"freekick_accuracy\",\n",
    "    \"long_passing\",\n",
    "    \"ball_control\",\n",
    "    \"acceleration\",\n",
    "    \"agility\",\n",
    "    \"shot_power\",\n",
    "    \"stamina\",\n",
    "    \"long_shots\",\n",
    "    \"interceptions\",\n",
    "    \"positioning\",\n",
    "    \"vision\",\n",
    "    \"marking\",\n",
    "    \"standing_tackle\",\n",
    "    \"custom_metric\"  # Include the new column\n",
    "]\n",
    "\n",
    "# Columns to include in the combined list\n",
    "columns_to_include = naive_class.header\n",
    "\n",
    "# Extract column indices and construct the combined list\n",
    "column_indices = [table.column_names.index(col) for col in columns_to_include if col in table.column_names]\n",
    "combined_list = [[row[idx] for idx in column_indices] for row in table.data]\n",
    "\n",
    "# Extract the target variable\n",
    "target = [row[-1] for row in balanced_data]  # Ensure target aligns with discretized_position\n",
    "\n",
    "# Perform analysis\n",
    "myutils.perform_analysis(combined_list, target, knn_classifier, dummy_classifier, naive_class, tree_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "\n",
    "This section must briefly describe the dataset you used and the classification task you implemented (e.g., what were you trying to classify in the dataset). You should also briefly describe your findings (e.g., what classifier approach performed the best)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis:\n",
    "\n",
    "1. Information about the dataset itself, e.g., the attributes and attribute types, the number of instances, and the attribute being used as the label.\n",
    "\n",
    "2. Relevant summary statistics about the dataset.\n",
    "\n",
    "3. Data visualizations highlighting important/interesting aspects of your dataset. Visualizations may include frequency distributions, comparisons of attributes (scatterplot, multiple frequency diagrams), box and whisker plots, etc. The goal is not to include all possible diagrams, but instead to select and highlight diagrams that provide insight about the dataset itself.\n",
    "\n",
    "4. Note that this section must describe the above (in paragraph form) and not just provide diagrams and statistics. Also, each figure included must have a figure caption (Figure number and textual description) that is referenced from the text (e.g., “Figure 2 shows a frequency diagram for ...”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results: \n",
    "\n",
    "This section should describe the classification approach you developed and its performance. Explain what techniques you used, briefly how you designed and implemented the classifiers, how you evaluated your classifiers’ predictive ability, and how well the classifiers performed. Thoroughly describe how you evaluated performance, the comparison results, and which classifier is “best”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Web App \n",
    "\n",
    " Create a Flask web app with this “best” classifier deployed with an API interface. For the base project (i.e., not bonus), your web app only has to run locally. Part of the bonus is to deploy your web app:\n",
    "\n",
    "1. BONUS (5 pts): Deploy your Flask web app to a free hosting service such as Render (you do not have to use Render, you may use a different service if you wish). In your repo README.md and your project report, include a link to a deployed web app hosting your Flask app.\n",
    "2. BONUS (3 pts): Add a user interface to your Flask web app on the index/homepage. The interface should allow the user to enter in attribute values for an unseen instance via a form, press a “Predict” button, and see the prediction for the instance. See the completed Flask-App-Demo repo on Github for a template of how to do this with Flask and a POST request (I will post this after we cover it in class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Conclusion: \n",
    "Provide a brief conclusion of your project, including a short summary of the dataset you used (and any of its inherent challenges for classification), the classification approach you developed, your classifiers’ performance, and any ideas you have on ways to improve its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments: \n",
    "This is where you should cite your sources, including any data, code, or materials that are outside of the scope of CPSC 322 (including previous course projects) that you used. As per the course syllabus, you also need to acknowledge any use of AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
